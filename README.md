# Waste_Classification
‚ôªÔ∏è Waste Classification with Computer Vision

This project explores the use of computer vision and deep learning to automatically classify waste into six common categories: cardboard, glass, metal, paper, plastic, and trash. The purpose of this system is to support automated recycling workflows by helping machines distinguish materials more accurately, which can reduce human sorting errors and improve sustainability initiatives. Incorrect waste classification is a major challenge in recycling facilities, often leading to contamination and lower recycling efficiency. By applying AI to this process, we aim to create a step forward toward smarter environmental systems capable of assisting or even replacing manual sorting tasks in real-world environments.

üöÄ Approach and Model Design

The model is developed using transfer learning with EfficientNet-B0, taking advantage of weights pretrained on the ImageNet dataset. This approach allows the model to learn efficiently from a relatively small dataset because it starts with strong general visual features already built in. During training, we apply data augmentation techniques to help the model generalize better to new images, as real waste images can vary widely in lighting, background, size, and condition. We also use class-weighted loss to handle any imbalance between categories, such as having more images for some materials than others. To avoid overfitting and improve training efficiency, an early stopping criteria is applied if the validation loss does not improve. Additionally, Grad-CAM heatmaps are integrated to visually highlight the regions of each image that influence the model's predictions, improving transparency and interpretability for users.

üìÇ Dataset and Training Environment

The dataset follows the TrashNet directory structure, organized into separate folders for train, validation, and test splits. Each split contains subfolders for the six class labels. This dataset structure is also compatible with automated loading through PyTorch's ImageFolder class. The project is built and executed in Google Colab, taking advantage of GPU resources when available. To make the notebook robust and beginner-friendly, it includes a synthetic fallback dataset that automatically activates if no dataset is detected in the expected path. This ensures that the full training, evaluation, and visualization pipeline can be executed even when real data is not yet available, which supports reproducibility and avoids notebook failure during demonstrations or testing.

üìä Evaluation and Performance Goals

Model performance is evaluated using standard machine learning metrics such as accuracy, precision, recall, and a confusion matrix to analyze class-by-class behavior. In addition to overall accuracy, the model aims to achieve strong recall for visually similar categories that are commonly confused, such as paper vs cardboard or plastic vs general trash. The performance goal for this project is 90%+ accuracy, representing a solid baseline for academic and prototype-level applications. Beyond accuracy alone, explainability through Grad-CAM heatmaps provides meaningful insight into how the model processes and interprets different images, ensuring the results are not only correct but also interpretable ‚Äî an important requirement when applying AI to real-world sustainability and waste-management tasks.

‚ñ∂Ô∏è Usage and Output

To run the system, users simply upload a dataset to the /content/data/ directory in Colab and execute the notebook cells. Once training completes, the notebook generates key outputs including loss curves, classification metrics, and heatmaps showing where the model is focusing its attention during prediction. Users can also upload their own waste images at the end of the notebook to see real-time predictions and visual explanations. The project ultimately produces a trained model file, performance reports, and sample interpretability visuals, making it suitable for both demonstration and further development‚Äîfor example, deploying into a smart bin prototype, a mobile recycling assistant, or a robotics platform for automated sorting.
